# This code (minute variance labeler) is run on the frame counts flags file
# generated by the spatial distribution labeler on E. coli cell datasets.
#
# This code labels the 'quality' of minutes of data based both on the quality
# of the images taken during that minute - as determined by the spatial
# distribution labeler - and the variance in the number of cells detected
# across images in this minute. Images taken during the same minute should
# have (by and large) the same cells, and therefore the same detected cell
# counts; exceptions to this indicate problems with the entire minute of data,
# either due to poor image quality overall or a fast-moving liquid flow,
# which cannot be segmented with any accuracy.
#
# This code only labels the 'quality' of each minute; it does not filter
# minutes out. Actual filtering based on this information is done in the
# next analysis program, the 'counts poisson judgment'. This code outputs
# a 'minutes variance flags' file.

import os
import numpy as np
import sys
from StringIO import StringIO

expLabel = sys.argv[1]
firstMinute = int(sys.argv[2])

path = os.path.join(expLabel,'temp_files')
datefolder=path
filename = 'minute_variance_flags'
filetype = '.csv'
try: 
    os.makedirs(path)
except OSError:
    if not os.path.isdir(path):
        raise


path = os.path.join(path,expLabel + '_' + filename)
f = open(path+filetype,'w')

# Import data
data_file = open(os.path.join(os.path.join(expLabel,'temp_files'),expLabel+'_frame_counts_flags.csv'),'r')

endOfFile=False # We're not at the end of the file

minute=firstMinute
counts=[] # Counts per frame
flags=[] # Spatial distribution flag of frame
while not endOfFile: # Until we reach the end of the file...
    for i in range(5): # Five frames per minute...
        try:
            line=data_file.readline() # Read in a line
            if line is None: # Break if line is empty
                endOfFile=True
                break
            line=np.genfromtxt(StringIO(line), delimiter=",") # Convert line to Numpy array
            if len(line)==0: # Break if array is empty
                endOfFile=True
                break
            # Note: each line of the data file represents a frame (image)
            #       with the following properties:
            # line[0] = minute  (data file ordered by this column)
            # line[1] = frame/image number within this minute (secondary ordering of data file by this column)
            # line[2] = number of cells detected
            # line[3] = spatial distribution flag
            
            # Save frame counts and flag data
            counts.append(line[2])
            flags.append(line[3])
        except: # Break if there's an exception
            endOfFile=True
            break
    removeFrames=[] # Are any images so 'unlikely' (as determined by spatial distribution labeler) as to be ignored?
    for i in reversed(range(len(flags))): # Search flags in reverse order to avoid issues with removing objects from list with changing size...
        if flags[i]>3: # If such an image would appear less than every 1 in 100,000 times by chance...
            removeFrames.append(i) # Ignore this image.
    for i in removeFrames: # Remove frames as determined above
        flags.pop(i)
        counts.pop(i)
    if len(flags)>2: # If this minute still has at least two frames left worth considering...
        flagAv=np.mean(flags) # Average value of remaining spatial distribution flags
    else:
        flagAv=4 # Effectively means this minute is 'bad'
    if len(flags)>2 and flagAv<2.5: # If this minute has at least two frames left with a reasonable chance of being normal...
        cMean=np.mean(counts) # Average number of cells across frames
        cStdev=np.std(counts) # Standard deviation of number of cells across frames
        # The rest of the code is designed to evaluate the likelihood of finding a minute of data
        # with a variance across frames like what was actually detected. This was determined
        # empirically, and a higher minute variance label (on a scale of 0-5) means a higher-than-expected
        # standard deviation. The standard deviation scales as the square root of the number of cells
        # so these numbers are first divided to cancel out effects based solely on number of cells
        # detected. This fraction is then compared to empirically determined numbers to determine
        # minute data quality; 0 = best, 5 = worst
        fraction=cStdev/np.sqrt(cMean)
        if fraction>1.9:
            f.write(str(minute)+","+str(cMean)+","+str(cStdev)+",5\n") 
        elif fraction>1.8:
            f.write(str(minute)+","+str(cMean)+","+str(cStdev)+",4\n") 
        elif fraction>1.7:
            f.write(str(minute)+","+str(cMean)+","+str(cStdev)+",3\n") 
        elif fraction>1.6:
            f.write(str(minute)+","+str(cMean)+","+str(cStdev)+",2\n") 
        elif fraction>1.5:
            f.write(str(minute)+","+str(cMean)+","+str(cStdev)+",1\n") 
        else:
            f.write(str(minute)+","+str(cMean)+","+str(cStdev)+",0\n") 
    else: # Label minute '5' (worst) and IGNORE NUMBER OF CELLS ENTIRELY if there are fewer than 2 good images or extremely poor quality images
        f.write(str(minute)+",0,0,5\n")
    
    minute+=1 # Go to next minute
    counts=[] # Clear lists
    flags=[]

f.close()